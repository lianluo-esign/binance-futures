# Gzip Historical Data Provider Configuration
# Reads compressed historical market data from .gz files

[provider]
# Provider identification - MUST match GzipProvider::CANONICAL_NAME
name = "gzip_historical_provider"  # MUST match GzipProvider::CANONICAL_NAME
type = "GzipProvider"              # MUST match GzipProvider::CANONICAL_TYPE
version = "1.0.0"

[data_source]
# Data source configuration
data_directory = "./data"
file_pattern = "*.gz"  # File pattern to match
symbols = ["BTCFDUSD"]  # Symbols to load
date_range_start = "2025-08-02"  # Optional: start date (YYYY-MM-DD)
date_range_end = "2025-08-07"    # Optional: end date (YYYY-MM-DD)

[files]
# Specific files to load (optional, overrides pattern matching)
# Leave empty to use file_pattern
specific_files = [
    "btcfdusd_20250802.gz",
    # "btcfdusd_20250803.gz",
]

[playback]
# Playback configuration
initial_speed = 1.0  # Playback speed multiplier
auto_start = true    # Start playback automatically
loop_enabled = false # Loop when reaching end of data
start_paused = false # Start in paused state

[parsing]
# Data parsing configuration
timestamp_format = "nanoseconds"  # nanoseconds, milliseconds, microseconds
line_delimiter = "\n"
field_separator = " "  # Space between timestamp and JSON
skip_invalid_lines = true
max_parse_errors = 100  # Stop after this many errors

[buffering]
# Buffer configuration for performance
read_buffer_size = 65536  # 64KB
decompress_buffer_size = 131072  # 128KB
event_buffer_size = 10000
prefetch_enabled = true
prefetch_size = 1000

[filtering]
# Data filtering options
filter_by_event_type = false
allowed_event_types = ["bookTicker", "trade", "depthUpdate"]
filter_by_time = false
time_start = 0  # Unix timestamp in milliseconds
time_end = 0    # Unix timestamp in milliseconds

[performance]
# Performance settings
use_parallel_decompression = false  # Enable for multi-file processing
thread_count = 2  # Number of decompression threads
cache_decompressed_data = false  # Cache in memory (uses more RAM)
cache_size_mb = 100  # Maximum cache size in MB

[error_handling]
# Error handling configuration
on_parse_error = "skip"  # skip, log, stop
on_file_error = "next"   # next, stop
max_consecutive_errors = 10
retry_on_error = true
retry_count = 3

[logging]
# Provider-specific logging
log_level = "info"
log_parsing_errors = true
log_performance_metrics = true
metrics_interval = 10000  # milliseconds
show_progress = true